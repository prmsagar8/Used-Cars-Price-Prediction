{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40b842b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time, sys\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1b643d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing webdriver\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a074732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urls to collect data from\n",
    "url1 = \"https://www.cars24.com/\"\n",
    "url2 = \"https://www.cardekho.com/\"\n",
    "url3 = \"https://www.ola.cars/\"\n",
    "url4 = \"https://www.olx.in/cars_c84\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff647d",
   "metadata": {},
   "source": [
    "# collecting data ----> cars24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c5f0afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cars24_search(search_term,location):\n",
    "    \"\"\"Generate a URL for search term with location\"\"\"\n",
    "    \n",
    "    LOC = {'Delhi': '110001', 'Noida': '201301', 'Gurgoan': '122001', 'Mumbai' : '400001', 'Pune': '411001', \n",
    "           'Banglore': '560001','Hyderabad': '500001', 'Chennai': '600001', 'Kolkata': '700001', 'Ahmedabad': '380001' }\n",
    "    \n",
    "    search_term = search_term.replace(' ','%20')\n",
    "    template = f'https://www.cars24.com/buy-used-car?sort=P&search={search_term}&storeCityId=8597&pinId={LOC[location]}'\n",
    "    \n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f152f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cars24_scrapping():\n",
    "    \"\"\" \n",
    "    Function to scrap datas from cars 24.\n",
    "    \n",
    "    \"\"\"\n",
    "      \n",
    "    print(\"SCRAPPING THE REQUIRED DETAILS\")\n",
    "    driver = webdriver.Chrome(r'../Car Price Prediction/chromedriver')\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    LOC = {'Delhi': '110001', 'Noida': '201301', 'Gurgoan': '122001', 'Mumbai' : '400001', 'Pune': '411001', \n",
    "           'Banglore': '560001','Hyderabad': '500001', 'Chennai': '600001', 'Kolkata': '700001', 'Ahmedabad': '380001' }\n",
    "    \n",
    "    location = [keys for keys in LOC.keys()]\n",
    "    \n",
    "    CARS= ['SUV', 'Sedan', 'Hatchback', 'Luxury Sedan', 'Luxury SUV']\n",
    "    \n",
    "    URL = [cars24_search(j,i) for i in location for j in CARS]\n",
    "    \n",
    "    LOCATION = []\n",
    "    MNF_YEAR = []\n",
    "    BRAND = []\n",
    "    MODEL = []\n",
    "    VARIANT = []\n",
    "    driven_KM = []\n",
    "    NOOF_owners = []\n",
    "    fuel_type = []\n",
    "    PRIZE = []\n",
    "\n",
    "\n",
    "    for i in URL:\n",
    "        driver.get(i)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(10)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        results = soup.find_all('div',{'class' : '_1l4fi'})\n",
    "\n",
    "        description = []\n",
    "        description1 = []\n",
    "        description2 = []\n",
    "        price = []\n",
    "    \n",
    "        for i in results:\n",
    "            description.append(i.find('h2', {'class': \"_3FpCg\"}).text)\n",
    "            description1.append(i.find('p', {'class': \"cvakB\"}).text)\n",
    "            description2.append(i.find('ul', {'class': \"bVR0c\"},'li').text)\n",
    "            price.append(i.find('div', {'class': \"_7udZZ\"}).text)\n",
    "            LOCATION.append(driver.find_element_by_xpath(\"//p[@class='_1OR7d']/label\").text)\n",
    "    \n",
    "    \n",
    "        year = [i.split(' ',2)[0] for i in description]\n",
    "        brand = [i.split(' ',2)[1] for i in description]\n",
    "        D1= [i.split(' ',2)[-1] for i in description]\n",
    "\n",
    "        for i in price:\n",
    "            PRIZE.append(i)\n",
    "\n",
    "        for i in year:\n",
    "            MNF_YEAR.append(i)\n",
    "        for i in brand:\n",
    "            BRAND.append(i)\n",
    "    \n",
    "        D2 = [i.rsplit(' ',1)[0] for i in description1]\n",
    "        variant = [i.split(' ') [-1]for i in description1]\n",
    "        for i in variant:\n",
    "            VARIANT.append(i)\n",
    "    \n",
    "        D3 = [D1[i]+' '+D2[i] for i in range(0,len(D1))]\n",
    "    \n",
    "        for i in D3:\n",
    "            MODEL.append(i)\n",
    "    \n",
    "        dummy1 = [i.split('km')[-1]for i in description2]\n",
    "        kms = [i.split('km')[0] for i in description2]\n",
    "        kms = [i+'km' for i in kms]\n",
    "\n",
    "        owners = [i.split('Owner')[0] for i in dummy1]\n",
    "        owners = [i+'Owner' for i in owners]\n",
    "        fuel = [i.split('Owner')[-1] for i in dummy1]\n",
    "\n",
    "        for i in kms:\n",
    "            driven_KM.append(i)\n",
    "\n",
    "        for i in owners:\n",
    "            NOOF_owners.append(i)\n",
    "\n",
    "        for i in fuel:\n",
    "            fuel_type.append(i)\n",
    "\n",
    "    driver.close()\n",
    "        \n",
    "    used_cars = pd.DataFrame({\"LOCATION\" : LOCATION,\n",
    "                              \"MNF_YEAR\" : MNF_YEAR,\n",
    "                              \"BRAND\" : BRAND,\n",
    "                              \"MODEL\" : MODEL,\n",
    "                              \"VARIANT\" : VARIANT,\n",
    "                              \"DRIVEN_KM\" : driven_KM,\n",
    "                              \"FUELTYPE\" : fuel_type,\n",
    "                              \"NOOF_OWNERS\" : NOOF_owners,\n",
    "                              \"PRICE\" : PRIZE\n",
    "                             })\n",
    "    \n",
    "    used_cars.to_csv(\"used_cars.csv\",index=False) #Creating CSV\n",
    "    print(\"SCRAPPED DETAILS ARE STORED AS 'used_cars.csv'\")\n",
    "    \n",
    "    return used_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d1d5c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRAPPING THE REQUIRED DETAILS\n",
      "SCRAPPED DETAILS ARE STORED AS 'used_cars.csv'\n"
     ]
    }
   ],
   "source": [
    "user_cars = cars24_scrapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23bb5a",
   "metadata": {},
   "source": [
    "## collecting data ----> cardekho used cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9f12788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from Car Dekho URL is: <Response [403]>\n"
     ]
    }
   ],
   "source": [
    "#response code\n",
    "page = requests.get(url2)\n",
    "print(\"Legality Response number from Car Dekho URL is:\", page) # response output code of the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72ad8c",
   "metadata": {},
   "source": [
    "##### for 403 response code we cannot perform web scraping in this stage and therefore we shall ignore the further process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc5f77",
   "metadata": {},
   "source": [
    "## collecting data ---> ola used cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "62dba605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from Ola Cars URL is: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#response code\n",
    "page = requests.get(url3)\n",
    "print(\"Legality Response number from Ola Cars URL is:\", page) # response output code of the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6d857",
   "metadata": {},
   "source": [
    "##### Even though the legality response is 200, we are unable to inspect the webpage since right click is disabled on the webpage, making web scraping is impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204976a",
   "metadata": {},
   "source": [
    "## collecting data ---> olx used cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "20de85f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from Olx Cars URL is: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#response code\n",
    "page = requests.get(url4, headers=headers)\n",
    "print(\"Legality Response number from Olx Cars URL is:\", page) # response output code of the webpage\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "0536dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see that the resoponse code we got 200 so we can grab the data.\n",
    "\n",
    "driver = webdriver.Chrome(r'../Car Price Prediction/chromedriver') # web drive\n",
    "driver.get(url4) # url4 is olx link\n",
    "driver.maximize_window()\n",
    "\n",
    "# variables --> creating empty lists\n",
    "location = []\n",
    "brand =[]\n",
    "year = []\n",
    "model = []\n",
    "kms_driven = []\n",
    "model = []\n",
    "variant = []\n",
    "km = []\n",
    "fuel = []\n",
    "owners = []\n",
    "price = []\n",
    "\n",
    "# getting the URL of the cars\n",
    "for i in range(0,500):\n",
    "    url=driver.find_elements_by_xpath(\"//li[@class='_31j8e']/a\")\n",
    "    for i in url:\n",
    "        prod_URL.append(i.get_attribute('href'))\n",
    "    try:\n",
    "        next_btn=driver.find_element_by_xpath(\"//button[@class='rui-39-wj rui-3evoE rui-1JPTg']\").click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "for i in prod_URL:\n",
    "    driver.get(i) \n",
    "\n",
    "    \n",
    "    #extracting location\n",
    "    loc = driver.find_elements_by_xpath(\"//div[@class='_1l939']/div[2]/div[2]/div[2]\")\n",
    "\n",
    "    try:\n",
    "        for i in loc:\n",
    "            t = i.text\n",
    "            location.append(t)\n",
    "    except NoSuchElementException as e:\n",
    "        location.append('-')\n",
    "        pass\n",
    "        \n",
    "    #Extracting brand and year by using only one xpath\n",
    "    brand_year= driver.find_elements_by_xpath(\"//div[@class='_35xN1']\")\n",
    "\n",
    "    try:\n",
    "        for i in brand_year:\n",
    "            t = i.text.split('(')[0]\n",
    "            brand.append(t)\n",
    "    except NoSuchElementException as e:\n",
    "        brand.append('-')\n",
    "        pass\n",
    "    \n",
    "    # extracting year\n",
    "\n",
    "    try:\n",
    "        for i in brand_year:\n",
    "            y = i.text.replace('(','')\n",
    "            y = y.replace(')','').split(' ')\n",
    "            y = ''.join(y[-1])\n",
    "            year.append(y)\n",
    "    except NoSuchElementException as e:\n",
    "        year.append('-')\n",
    "        pass\n",
    "        \n",
    "    #extracting model\n",
    "    mod =driver.find_elements_by_xpath(\"//*[@id='container']/main/div/div/div/div[5]/div[1]/div[1]/div[1]/div/div[3]\")\n",
    "\n",
    "    try:\n",
    "        for i in mod:\n",
    "            model.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        model.append('-')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    #variant\n",
    "    var = driver.find_elements_by_xpath(\"//div[@class='aOxkz']/div[3]/div\")\n",
    "\n",
    "    try:\n",
    "        for i in var:\n",
    "            variant.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        variant.append('-')\n",
    "        pass\n",
    "        \n",
    "    #Extracting km driven\n",
    "    km_driven = driver.find_elements_by_xpath(\"//div[@class='aOxkz']/div[2]/div\")\n",
    "    \n",
    "    try:\n",
    "        for i in km_driven:\n",
    "            km.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        km.append('-')\n",
    "        pass\n",
    "    \n",
    "    #extracting fuel \n",
    "    oil =driver.find_elements_by_xpath(\"//div[@class='aOxkz']/div[1]/div\")\n",
    "\n",
    "    try:\n",
    "        for i in oil:\n",
    "            fuel.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        fuel.append('-')\n",
    "        pass\n",
    "        \n",
    "    #no of owners\n",
    "    noofowners = driver.find_elements_by_xpath(\"//div[@class='_1l939']/div[1]/div[2]/div[2]\")\n",
    "\n",
    "    try:\n",
    "        for i in noofowners:\n",
    "            owners.append(i.text)\n",
    "    except NoSuchElementExcpetion as e:\n",
    "        owners.append('-')\n",
    "        pass\n",
    "\n",
    "\n",
    "    #price\n",
    "    cost = driver.find_elements_by_xpath(\"//div[@class='_3FkyT']\")\n",
    "\n",
    "    try:\n",
    "        for i in cost:\n",
    "            price.append(i.text.strip('â‚¹ '))\n",
    "    except NoSuchElementExcpetion as e:\n",
    "        price.append('-')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "26e0bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4526, 4526, 4526, 4526, 4526, 4526, 4526, 4526, 4526)"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking collected data size in each column\n",
    "len(location),len(year),len(brand),len(model),len(variant),len(km), len(fuel), len(owners),len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "ad4129c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe\n",
    "used_cars = pd.DataFrame({\"LOCATION\" : location,\n",
    "                          \"MNF_YEAR\" : year,\n",
    "                          \"BRAND\" : brand,\n",
    "                          \"MODEL\" : model,\n",
    "                          \"VARIANT\" : variant,\n",
    "                          \"DRIVEN_KM\" : km,\n",
    "                          \"FUELTYPE\" : fuel,\n",
    "                          \"NOOF_OWNERS\" : owners,\n",
    "                          \"PRICE\" : price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "a1a955db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to csv file\n",
    "used_cars.to_csv(\"Used_Car_olx_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
